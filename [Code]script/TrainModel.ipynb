{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f7c0efec02448a6a07ee8c6a6361779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_22e93f24f60747dcb8c107d3cbbd08d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0db4c68ebfe9406d978f022b3f92994c",
              "IPY_MODEL_57139f31b67840829f2af2471694e883"
            ]
          }
        },
        "22e93f24f60747dcb8c107d3cbbd08d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0db4c68ebfe9406d978f022b3f92994c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6e8d5ae1a7a746fa9d9eba79aad33f22",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34d64b2dbafe4bc485aa02eb6727226b"
          }
        },
        "57139f31b67840829f2af2471694e883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8058b66e449a46c196db99d2ad16effe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 848B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d254a8eb93444378c812a0b25f149ae"
          }
        },
        "6e8d5ae1a7a746fa9d9eba79aad33f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34d64b2dbafe4bc485aa02eb6727226b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8058b66e449a46c196db99d2ad16effe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d254a8eb93444378c812a0b25f149ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eff4cdecd5f46899a42436966c3f29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_279491188e724a27a95e802ae5908c27",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_201f23e8d87442bf94128e72265a1614",
              "IPY_MODEL_05db1272e9e54585a8188ccde959ef0c"
            ]
          }
        },
        "279491188e724a27a95e802ae5908c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "201f23e8d87442bf94128e72265a1614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d5cf9509b2b415a910c390c2aa0dfda",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3465644b889a4af8aeff86813b3e5566"
          }
        },
        "05db1272e9e54585a8188ccde959ef0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc44829fa30e46f495fcb9e415a9fe67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:50&lt;00:00, 8.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_557ce28fe26c4ccabc72dbacf4fcbf6a"
          }
        },
        "1d5cf9509b2b415a910c390c2aa0dfda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3465644b889a4af8aeff86813b3e5566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc44829fa30e46f495fcb9e415a9fe67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "557ce28fe26c4ccabc72dbacf4fcbf6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKpfLpfFxQMH",
        "outputId": "ea9ef12b-cf96-48ed-c77f-a09b4dc9c65a"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd #\n",
        "import nltk\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "g8dBUiGbxV68",
        "outputId": "4a75072f-9c64-4421-ba84-18093994e4ef"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/Corona_NLP_train.csv',encoding='latin_1')\n",
        "train_data.head()\n",
        "train_data.drop_duplicates(inplace= True)\n",
        "train_data.dropna(inplace=True)\n",
        "\n",
        "# load stop words\n",
        "nltk.download('stopwords')\n",
        "stop_word = stopwords.words('english')\n",
        "def clean(text):\n",
        "    #     remove urls\n",
        "    text = re.sub(r'http\\S+', \" \", text)\n",
        "\n",
        "    #     remove mentions\n",
        "    text = re.sub(r'@\\w+',' ',text)\n",
        "\n",
        "    #     remove hastags\n",
        "    text = re.sub(r'#\\w+', ' ', text)\n",
        "\n",
        "    #     remove digits\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    #     remove html tags\n",
        "    text = re.sub('r<.*?>',' ', text)\n",
        "    \n",
        "    #     remove stop words \n",
        "    text = text.split()\n",
        "    text = \" \".join([word for word in text if not word in stop_word])\n",
        "    \n",
        "      \n",
        "    return text\n",
        "\n",
        "train_data['OriginalTweet'] = train_data['OriginalTweet'].apply(lambda x: clean(x))\n",
        "\n",
        "#l = {\"Neutral\":0, \"Positive\":1,\"Extremely Positive\":2,\"Negative\":3,\"Extremely Negative\":4}\n",
        "l = {\"Neutral\":0, \"Positive\":1,\"Extremely Positive\":1,\"Negative\":2,\"Extremely Negative\":2}\n",
        "train_data['Sentiment'] = train_data['Sentiment'].map(l)\n",
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk neighbours family exchange phone n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths give elderly...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3804</td>\n",
              "      <td>48756</td>\n",
              "      <td>ÃƒÂœT: 36.319708,-82.363649</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>As news regionÃ‚Â’s first confirmed COVID- case ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3805</td>\n",
              "      <td>48757</td>\n",
              "      <td>35.926541,-78.753267</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Cashier grocery store sharing insights To prov...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UserName  ...  Sentiment\n",
              "0      3799  ...          0\n",
              "1      3800  ...          1\n",
              "2      3801  ...          1\n",
              "5      3804  ...          1\n",
              "6      3805  ...          1\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr-KYVaLxzlY"
      },
      "source": [
        "x_train = train_data['OriginalTweet'].copy()\n",
        "y_train = train_data['Sentiment'].copy()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v8XvSUIxz8e"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SKaAt9_x1-O",
        "outputId": "e06ea273-1ae2-43a7-8b38-d250c077d060"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "sentences = x_train.to_list()\n",
        "labels = y_train.to_list()\n",
        "\n",
        "#torch \n",
        "max_len = 0\n",
        "for sent in x_train.to_list():\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in x_train.to_list():\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,\n",
        "                        truncation=True,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gco27Hitx6sO",
        "outputId": "85820fb9-7c72-448c-e7a9-bbc90e10c4fe"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(y_train.to_list())\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  \n",
            "Token IDs: tensor([101, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI0KGoa9x-_j",
        "outputId": "2fe561a7-fffe-4e48-f658-a8e7c67ed69d"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29,310 training samples\n",
            "3,257 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815,
          "referenced_widgets": [
            "9f7c0efec02448a6a07ee8c6a6361779",
            "22e93f24f60747dcb8c107d3cbbd08d0",
            "0db4c68ebfe9406d978f022b3f92994c",
            "57139f31b67840829f2af2471694e883",
            "6e8d5ae1a7a746fa9d9eba79aad33f22",
            "34d64b2dbafe4bc485aa02eb6727226b",
            "8058b66e449a46c196db99d2ad16effe",
            "0d254a8eb93444378c812a0b25f149ae",
            "4eff4cdecd5f46899a42436966c3f29c",
            "279491188e724a27a95e802ae5908c27",
            "201f23e8d87442bf94128e72265a1614",
            "05db1272e9e54585a8188ccde959ef0c",
            "1d5cf9509b2b415a910c390c2aa0dfda",
            "3465644b889a4af8aeff86813b3e5566",
            "bc44829fa30e46f495fcb9e415a9fe67",
            "557ce28fe26c4ccabc72dbacf4fcbf6a"
          ]
        },
        "id": "du6_EE8ryHaj",
        "outputId": "3fb2c78c-05b0-44e0-d698-1d1e03d432ad"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n",
        "\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f7c0efec02448a6a07ee8c6a6361779",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eff4cdecd5f46899a42436966c3f29c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (3, 768)\n",
            "classifier.bias                                                 (3,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yESahr5ycj8",
        "outputId": "0e833616-f4ba-4510-acad-92f25adf0047"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1-Pzb3Ayc81"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSKPrrwpz3ng",
        "outputId": "0725496a-496e-44f9-ff22-4da3f19ce7b5"
      },
      "source": [
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        res = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = res.loss \n",
        "        logits = res.logits\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "          res = model(b_input_ids, \n",
        "                      token_type_ids=None, \n",
        "                      attention_mask=b_input_mask,\n",
        "                      labels=b_labels)\n",
        "          loss = res.loss\n",
        "          logits = res.logits   \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    916.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    916.    Elapsed: 0:00:27.\n",
            "  Batch   120  of    916.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    916.    Elapsed: 0:00:55.\n",
            "  Batch   200  of    916.    Elapsed: 0:01:10.\n",
            "  Batch   240  of    916.    Elapsed: 0:01:24.\n",
            "  Batch   280  of    916.    Elapsed: 0:01:39.\n",
            "  Batch   320  of    916.    Elapsed: 0:01:54.\n",
            "  Batch   360  of    916.    Elapsed: 0:02:10.\n",
            "  Batch   400  of    916.    Elapsed: 0:02:25.\n",
            "  Batch   440  of    916.    Elapsed: 0:02:40.\n",
            "  Batch   480  of    916.    Elapsed: 0:02:55.\n",
            "  Batch   520  of    916.    Elapsed: 0:03:11.\n",
            "  Batch   560  of    916.    Elapsed: 0:03:26.\n",
            "  Batch   600  of    916.    Elapsed: 0:03:41.\n",
            "  Batch   640  of    916.    Elapsed: 0:03:57.\n",
            "  Batch   680  of    916.    Elapsed: 0:04:12.\n",
            "  Batch   720  of    916.    Elapsed: 0:04:27.\n",
            "  Batch   760  of    916.    Elapsed: 0:04:42.\n",
            "  Batch   800  of    916.    Elapsed: 0:04:58.\n",
            "  Batch   840  of    916.    Elapsed: 0:05:13.\n",
            "  Batch   880  of    916.    Elapsed: 0:05:28.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:05:42\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.38\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    916.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    916.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    916.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    916.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    916.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    916.    Elapsed: 0:01:31.\n",
            "  Batch   280  of    916.    Elapsed: 0:01:47.\n",
            "  Batch   320  of    916.    Elapsed: 0:02:02.\n",
            "  Batch   360  of    916.    Elapsed: 0:02:17.\n",
            "  Batch   400  of    916.    Elapsed: 0:02:32.\n",
            "  Batch   440  of    916.    Elapsed: 0:02:48.\n",
            "  Batch   480  of    916.    Elapsed: 0:03:03.\n",
            "  Batch   520  of    916.    Elapsed: 0:03:18.\n",
            "  Batch   560  of    916.    Elapsed: 0:03:33.\n",
            "  Batch   600  of    916.    Elapsed: 0:03:48.\n",
            "  Batch   640  of    916.    Elapsed: 0:04:04.\n",
            "  Batch   680  of    916.    Elapsed: 0:04:19.\n",
            "  Batch   720  of    916.    Elapsed: 0:04:34.\n",
            "  Batch   760  of    916.    Elapsed: 0:04:49.\n",
            "  Batch   800  of    916.    Elapsed: 0:05:05.\n",
            "  Batch   840  of    916.    Elapsed: 0:05:20.\n",
            "  Batch   880  of    916.    Elapsed: 0:05:35.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:05:49\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 0.34\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    916.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    916.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    916.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    916.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    916.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    916.    Elapsed: 0:01:31.\n",
            "  Batch   280  of    916.    Elapsed: 0:01:47.\n",
            "  Batch   320  of    916.    Elapsed: 0:02:02.\n",
            "  Batch   360  of    916.    Elapsed: 0:02:17.\n",
            "  Batch   400  of    916.    Elapsed: 0:02:32.\n",
            "  Batch   440  of    916.    Elapsed: 0:02:47.\n",
            "  Batch   480  of    916.    Elapsed: 0:03:02.\n",
            "  Batch   520  of    916.    Elapsed: 0:03:18.\n",
            "  Batch   560  of    916.    Elapsed: 0:03:33.\n",
            "  Batch   600  of    916.    Elapsed: 0:03:48.\n",
            "  Batch   640  of    916.    Elapsed: 0:04:03.\n",
            "  Batch   680  of    916.    Elapsed: 0:04:18.\n",
            "  Batch   720  of    916.    Elapsed: 0:04:34.\n",
            "  Batch   760  of    916.    Elapsed: 0:04:49.\n",
            "  Batch   800  of    916.    Elapsed: 0:05:04.\n",
            "  Batch   840  of    916.    Elapsed: 0:05:19.\n",
            "  Batch   880  of    916.    Elapsed: 0:05:34.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.34\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    916.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    916.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    916.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    916.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    916.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    916.    Elapsed: 0:01:31.\n",
            "  Batch   280  of    916.    Elapsed: 0:01:46.\n",
            "  Batch   320  of    916.    Elapsed: 0:02:02.\n",
            "  Batch   360  of    916.    Elapsed: 0:02:17.\n",
            "  Batch   400  of    916.    Elapsed: 0:02:32.\n",
            "  Batch   440  of    916.    Elapsed: 0:02:47.\n",
            "  Batch   480  of    916.    Elapsed: 0:03:03.\n",
            "  Batch   520  of    916.    Elapsed: 0:03:18.\n",
            "  Batch   560  of    916.    Elapsed: 0:03:33.\n",
            "  Batch   600  of    916.    Elapsed: 0:03:48.\n",
            "  Batch   640  of    916.    Elapsed: 0:04:03.\n",
            "  Batch   680  of    916.    Elapsed: 0:04:18.\n",
            "  Batch   720  of    916.    Elapsed: 0:04:34.\n",
            "  Batch   760  of    916.    Elapsed: 0:04:49.\n",
            "  Batch   800  of    916.    Elapsed: 0:05:04.\n",
            "  Batch   840  of    916.    Elapsed: 0:05:19.\n",
            "  Batch   880  of    916.    Elapsed: 0:05:34.\n",
            "\n",
            "  Average training loss: 0.17\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.35\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:23:58 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQxczDLz-_vz"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats\n",
        "df_stats.to_csv(\"/content/drive/MyDrive/train_bert.cvs\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "rgKAImnT3W7z",
        "outputId": "a61c8f6a-1fbb-4518-f66c-588659e1e43e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch7gTRBm_f6a"
      },
      "source": [
        "    save_path = \"/content/model_2.pt\"\n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': avg_val_loss}\n",
        "    torch.save(state_dict, save_path)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5S4t1UcBVh7",
        "outputId": "db4833a5-c606-4d36-d251-48e52fec4879"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "\n",
        "labels = train_data['Sentiment'].tolist()\n",
        "for sent in train_data[\"OriginalTweet\"].tolist():\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,\n",
        "                        truncation=True,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 64\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtXxLUgABtne"
      },
      "source": [
        "checkpoint = torch.load(\"/content/drive/MyDrive/model_2.pt\")\n",
        "\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  pred_labels_i = np.argmax(logits, axis=1).flatten()\n",
        "  predictions = predictions + list(pred_labels_i)\n",
        "  true_labels = true_labels + list(label_ids)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQuUgIeoI0d7"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTnMLpqCI966",
        "outputId": "d4194be2-0e3e-4cc1-e875-f90e1ebd9b66"
      },
      "source": [
        "confusion_matrix(true_labels,predictions)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5573,   305,   294],\n",
              "       [  124, 13954,   305],\n",
              "       [  143,   281, 11588]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}